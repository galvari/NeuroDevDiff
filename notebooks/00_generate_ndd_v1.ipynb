{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31259,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": false
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NeuroDevDiff — dataset generation (v1)\n\nThis notebook generates **NeuroDevDiff v1**: synthetic pediatric neurodevelopmental referral vignettes for experimenting with\nAI-assisted decision support under uncertainty.\n\nOutputs are saved under `data/` (CSV + JSONL + metadata).\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T15:32:38.771712Z",
     "start_time": "2026-02-10T15:32:38.280129Z"
    }
   },
   "source": [
    "from __future__ import annotations\n\nimport random\nimport pandas as pd\n\nSEED = 42\nN_CASES = 2000\nNOISE_LEVEL = 1.0  # keep fixed for reproducibility\n\nrandom.seed(SEED)\n\n# --------------------------\n# 1) Archetypes (neurodevelopment differential)\n# --------------------------\nARCHETYPES = {\n  \"ASD\": {\n    \"symptoms\": {\n      \"social\": [\"reduced reciprocity\", \"poor peer interaction\", \"limited social initiation\"],\n      \"language\": [\"pragmatic difficulties\", \"literal interpretation\", \"atypical prosody\"],\n      \"rrb\": [\"rigid routines\", \"restricted interests\", \"repetitive behaviors\"],\n      \"sensory\": [\"sensory sensitivity\", \"sensory seeking\"]\n    },\n    \"base_comorb\": {\"ADHD\": 0.25, \"ANXIETY\": 0.20, \"SLD\": 0.10},\n    \"weights\": 0.20\n  },\n  \"ADHD\": {\n    \"symptoms\": {\n      \"attention\": [\"inattention\", \"disorganization\", \"forgetfulness\"],\n      \"behavior\": [\"impulsivity\", \"restlessness\", \"interrupting others\"],\n      \"school\": [\"homework incomplete\", \"poor sustained effort\"]\n    },\n    \"base_comorb\": {\"ANXIETY\": 0.15, \"ASD\": 0.15, \"SLD\": 0.20},\n    \"weights\": 0.18\n  },\n  \"OCD\": {\n    \"symptoms\": {\n      \"anxiety\": [\"intrusive thoughts\", \"high distress with uncertainty\"],\n      \"compulsions\": [\"checking\", \"washing\", \"counting\", \"reassurance seeking\"],\n      \"avoidance\": [\"avoid triggers\", \"ritual-dependent routines\"]\n    },\n    \"base_comorb\": {\"ANXIETY\": 0.25, \"ASD\": 0.10},\n    \"weights\": 0.10\n  },\n  \"ANXIETY\": {\n    \"symptoms\": {\n      \"anxiety\": [\"worry\", \"avoidance\", \"somatic complaints\", \"sleep difficulties\"],\n      \"school\": [\"school refusal\", \"performance fear\"],\n      \"social\": [\"shy/withdrawn in novel contexts\"]\n    },\n    \"base_comorb\": {\"ADHD\": 0.10, \"ASD\": 0.10, \"SELECTIVE_MUTISM\": 0.12},\n    \"weights\": 0.16\n  },\n  \"SELECTIVE_MUTISM\": {\n    \"symptoms\": {\n      \"communication\": [\"speaks at home but not at school\", \"freezes in social settings\"],\n      \"anxiety\": [\"high social inhibition\", \"avoidance of speaking\"],\n      \"school\": [\"teacher reports silence\"]\n    },\n    \"base_comorb\": {\"ANXIETY\": 0.35, \"ASD\": 0.10},\n    \"weights\": 0.08\n  },\n  \"SLD\": {\n    \"symptoms\": {\n      \"learning\": [\"reading difficulties\", \"spelling errors\", \"math difficulties\"],\n      \"school\": [\"slow progress despite effort\", \"avoidance of homework\"],\n      \"emotional\": [\"frustration\", \"low self-esteem\"]\n    },\n    \"base_comorb\": {\"ADHD\": 0.25, \"ANXIETY\": 0.15},\n    \"weights\": 0.14\n  },\n  \"GDD_ID\": {\n    \"symptoms\": {\n      \"development\": [\"delayed milestones\", \"adaptive difficulties\", \"global learning delays\"],\n      \"language\": [\"language delay\", \"limited vocabulary for age\"],\n      \"motor\": [\"poor coordination\"]\n    },\n    \"base_comorb\": {\"ASD\": 0.15, \"ANXIETY\": 0.05},\n    \"weights\": 0.07\n  },\n  \"NDD_UNSPEC\": {\n    \"symptoms\": {\n      \"mixed\": [\"mixed difficulties across domains\", \"unclear onset\", \"inconsistent reports\"],\n      \"attention\": [\"variable attention\"],\n      \"social\": [\"social withdrawal in some contexts\"]\n    },\n    \"base_comorb\": {\"ASD\": 0.10, \"ADHD\": 0.10, \"ANXIETY\": 0.10},\n    \"weights\": 0.07\n  }\n}\n\nRED_FLAGS = [\n  \"self-harm thoughts\",\n  \"acute aggression risk\",\n  \"psychotic-like symptoms\"\n]\n\n# --------------------------\n# 2) Cognitive profiles (WISC/Griffith-style), scaled 1–19\n# --------------------------\ndef _score(mean, spread=2, low=1, high=19):\n    return int(min(high, max(low, random.gauss(mean, spread))))\n\nCOGNITIVE_PROFILES = {\n    \"ASD\": {\n        \"verbal_language\": (8, 2),\n        \"visuospatial\": (12, 2),\n        \"working_memory\": (7, 2),\n        \"processing_speed\": (6, 2),\n        \"attention\": (8, 3),\n        \"motor\": (9, 3)\n    },\n    \"ADHD\": {\n        \"verbal_language\": (10, 2),\n        \"visuospatial\": (10, 2),\n        \"working_memory\": (7, 2),\n        \"processing_speed\": (7, 2),\n        \"attention\": (5, 2),\n        \"motor\": (10, 3)\n    },\n    \"OCD\": {\n        \"verbal_language\": (12, 2),\n        \"visuospatial\": (10, 2),\n        \"working_memory\": (10, 2),\n        \"processing_speed\": (8, 2),\n        \"attention\": (10, 2),\n        \"motor\": (10, 2)\n    },\n    \"ANXIETY\": {\n        \"verbal_language\": (10, 2),\n        \"visuospatial\": (10, 2),\n        \"working_memory\": (9, 2),\n        \"processing_speed\": (8, 2),\n        \"attention\": (9, 2),\n        \"motor\": (10, 2)\n    },\n    \"SELECTIVE_MUTISM\": {\n        \"verbal_language\": (9, 2),\n        \"visuospatial\": (10, 2),\n        \"working_memory\": (9, 2),\n        \"processing_speed\": (8, 2),\n        \"attention\": (9, 2),\n        \"motor\": (10, 2)\n    },\n    \"SLD\": {\n        \"verbal_language\": (10, 1.5),\n        \"visuospatial\": (10, 1.5),\n        \"working_memory\": (10, 1.5),\n        \"processing_speed\": (10, 1.5),\n        \"attention\": (10, 1.5),\n        \"motor\": (10, 1.5)\n    },\n    \"GDD_ID\": {\n        \"verbal_language\": (4, 1),\n        \"visuospatial\": (4, 1),\n        \"working_memory\": (4, 1),\n        \"processing_speed\": (4, 1),\n        \"attention\": (4, 1),\n        \"motor\": (4, 1)\n    },\n    \"NDD_UNSPEC\": {\n        \"verbal_language\": (8, 3),\n        \"visuospatial\": (8, 3),\n        \"working_memory\": (8, 3),\n        \"processing_speed\": (8, 3),\n        \"attention\": (8, 3),\n        \"motor\": (8, 3)\n    }\n}\n\ndef _cognitive_pattern(scores: dict) -> str:\n    mx, mn = max(scores.values()), min(scores.values())\n    var = mx - mn\n    if var < 3 and mx <= 6:\n        return \"homogeneous_low\"\n    if var < 3:\n        return \"homogeneous_average\"\n    return \"dishomogeneous\"\n\n# --------------------------\n# 3) Realistic overlap + nonspecific symptoms (controlled noise)\n# --------------------------\nNON_SPECIFIC = [\n  (\"sleep\", \"sleep difficulties\"),\n  (\"emotional\", \"irritability\"),\n  (\"attention\", \"concentration problems\"),\n  (\"emotional\", \"low frustration tolerance\"),\n]\n\nNEIGHBORS = {\n  \"ASD\": [\"ADHD\",\"ANXIETY\",\"OCD\"],\n  \"ADHD\": [\"ASD\",\"ANXIETY\",\"SLD\"],\n  \"ANXIETY\": [\"OCD\",\"SELECTIVE_MUTISM\",\"ADHD\"],\n  \"OCD\": [\"ANXIETY\",\"ASD\"],\n  \"SELECTIVE_MUTISM\": [\"ANXIETY\",\"ASD\"],\n  \"SLD\": [\"ADHD\",\"ANXIETY\"],\n  \"GDD_ID\": [\"ASD\",\"NDD_UNSPEC\"],\n  \"NDD_UNSPEC\": [\"ASD\",\"ADHD\",\"ANXIETY\"]\n}\n\n# --------------------------\n# 4) Helpers\n# --------------------------\ndef _pick_symptoms(symptom_dict, k=4):\n    all_items = []\n    for dom, items in symptom_dict.items():\n        all_items.extend([(dom, s) for s in items])\n    picks = random.sample(all_items, k=min(k, len(all_items)))\n    return picks  # list of (domain, symptom)\n\ndef _sample_comorbidity(base_comorb):\n    comorbid = []\n    for dx, p in base_comorb.items():\n        if random.random() < p:\n            comorbid.append(dx)\n    return sorted(set(comorbid))\n\n# --------------------------\n# 5) Case generator\n# --------------------------\ndef make_case(i, noise_level=1.0):\n    age = random.choice([5, 6, 7, 8, 9, 10, 11, 12])\n    sex = random.choice([\"M\", \"F\"])\n\n    labels = list(ARCHETYPES.keys())\n    weights = [ARCHETYPES[k][\"weights\"] for k in labels]\n    true_dx = random.choices(labels, weights=weights, k=1)[0]\n    base = ARCHETYPES[true_dx]\n\n    severity = random.choices([\"mild\",\"moderate\",\"severe\"], weights=[0.35,0.45,0.20])[0]\n    context = random.choice([\"preschool\", \"primary school\", \"home+school\"])\n    duration = random.choice([\"3 months\",\"6 months\",\"1 year\",\"since early childhood\"])\n\n    core_sym = _pick_symptoms(base[\"symptoms\"], k=4)\n    comorbid = _sample_comorbidity(base[\"base_comorb\"])\n\n    # add nonspecific symptoms (common in clinical reality)\n    if random.random() < 0.65 * noise_level:\n        core_sym.append(random.choice(NON_SPECIFIC))\n\n    # add \"neighbor\" symptom contamination (controlled overlap)\n    if random.random() < 0.25 * noise_level:\n        neigh = random.choice(NEIGHBORS[true_dx])\n        core_sym.extend(_pick_symptoms(ARCHETYPES[neigh][\"symptoms\"], k=1))\n\n    # if comorbidity exists, sometimes it dominates presentation\n    if comorbid and random.random() < 0.15 * noise_level:\n        dominant = random.choice(comorbid)\n        core_sym.extend(_pick_symptoms(ARCHETYPES[dominant][\"symptoms\"], k=1))\n\n    # clinical missingness (not uniform)\n    onset_described = random.random() < 0.80\n    cross_setting = random.random() < (0.82 if true_dx in [\"ASD\",\"ADHD\",\"GDD_ID\"] else 0.68)\n    functioning_described = random.random() < (0.75 if severity != \"mild\" else 0.60)\n\n    has_teacher_report = random.random() < 0.85\n    has_dev_history = random.random() < 0.70\n    has_language_assessment = random.random() < 0.50\n    has_learning_assessment = random.random() < 0.45\n\n    # rare risk flags (keep low; child NDD)\n    risk_high = random.random() < 0.035\n    red_flags = [random.choice(RED_FLAGS)] if risk_high else []\n\n    # differential shortlist\n    diff = set()\n    if true_dx == \"ASD\": diff.update([\"ADHD\", \"ANXIETY\"])\n    if true_dx == \"ADHD\": diff.update([\"SLD\", \"ANXIETY\", \"ASD\"])\n    if true_dx == \"SLD\": diff.update([\"ADHD\", \"ANXIETY\"])\n    if true_dx == \"OCD\": diff.update([\"ANXIETY\", \"ASD\"])\n    if true_dx == \"SELECTIVE_MUTISM\": diff.update([\"ANXIETY\", \"ASD\"])\n    if true_dx == \"GDD_ID\": diff.update([\"ASD\", \"NDD_UNSPEC\"])\n    if true_dx == \"NDD_UNSPEC\": diff.update([\"ASD\", \"ADHD\", \"ANXIETY\"])\n\n    diff.update(comorbid)\n    diff.discard(true_dx)\n    plausible_alternatives = sorted(list(diff))[:3]\n\n    # cognitive profile\n    prof = COGNITIVE_PROFILES[true_dx]\n    cognitive_scores = {k: _score(mean=v[0], spread=v[1]) for k, v in prof.items()}\n\n    # cognitive \"variant\" noise (keeps realism; prevents barcode learning)\n    if true_dx == \"ASD\" and random.random() < 0.20 * noise_level:\n        for k in cognitive_scores:\n            cognitive_scores[k] = _score(9, 2)\n    if true_dx == \"ADHD\" and random.random() < 0.15 * noise_level:\n        for k in cognitive_scores:\n            cognitive_scores[k] = _score(10, 1.5)\n    if true_dx == \"SLD\" and random.random() < 0.10 * noise_level:\n        cognitive_scores[\"working_memory\"] = _score(8, 2)\n        cognitive_scores[\"processing_speed\"] = _score(8, 2)\n\n    cognitive_pattern = _cognitive_pattern(cognitive_scores)\n\n    # missing info list tailored to differential\n    missing = []\n    if not onset_described: missing.append(\"onset timeline\")\n    if not functioning_described: missing.append(\"functional impairment details\")\n    if not cross_setting: missing.append(\"cross-setting symptoms (home vs school)\")\n    if not has_teacher_report: missing.append(\"teacher report\")\n    if not has_dev_history: missing.append(\"developmental history\")\n    if (true_dx in [\"ASD\",\"SELECTIVE_MUTISM\"] or \"ASD\" in plausible_alternatives) and not has_language_assessment:\n        missing.append(\"language/pragmatics assessment\")\n    if (true_dx == \"SLD\" or \"SLD\" in plausible_alternatives) and not has_learning_assessment:\n        missing.append(\"learning assessment (reading/writing/math)\")\n\n    # defer policy (tuned to avoid absurdly high defer-rate)\n    critical_missing = (not onset_described) or (not functioning_described)\n    high_ambiguity = (len(plausible_alternatives) >= 3) and (severity != \"severe\") and (len(missing) >= 2)\n\n    if risk_high or critical_missing:\n        should_defer = 1\n    elif high_ambiguity:\n        should_defer = 1 if random.random() < 0.60 else 0\n    else:\n        should_defer = 1 if random.random() < 0.15 else 0\n\n    return {\n        \"case_id\": i,\n        \"age\": age,\n        \"sex\": sex,\n        \"context\": context,\n        \"duration\": duration,\n        \"severity\": severity,\n        \"true_profile\": true_dx,\n        \"comorbidity\": comorbid,\n        \"plausible_alternatives\": plausible_alternatives,\n        \"symptoms\": core_sym,   # list of (domain, symptom)\n        \"red_flags\": red_flags,\n        \"missing_info_list\": missing,\n        \"info\": {\n            \"onset_described\": onset_described,\n            \"cross_setting\": cross_setting,\n            \"functioning_described\": functioning_described,\n            \"teacher_report\": has_teacher_report,\n            \"developmental_history\": has_dev_history,\n            \"language_assessment\": has_language_assessment,\n            \"learning_assessment\": has_learning_assessment\n        },\n        \"cognitive_profile\": cognitive_scores,\n        \"cognitive_pattern\": cognitive_pattern,\n        \"labels\": {\"should_defer\": should_defer, \"risk_high\": int(risk_high)}\n    }\n\n# --------------------------\n# 6) Generate dataset + dataframe (v1.0)\n# --------------------------\nN = N_CASES\nNOISE_LEVEL = 1.0  # keep fixed for v1.0 reproducibility\n\ncases = [make_case(i, noise_level=NOISE_LEVEL) for i in range(1, N+1)]\n\ndf = pd.DataFrame([{\n    \"case_id\": c[\"case_id\"],\n    \"age\": c[\"age\"],\n    \"sex\": c[\"sex\"],\n    \"context\": c[\"context\"],\n    \"duration\": c[\"duration\"],\n    \"severity\": c[\"severity\"],\n    \"true_profile\": c[\"true_profile\"],\n    \"comorbidity\": \", \".join(c[\"comorbidity\"]) if c[\"comorbidity\"] else \"\",\n    \"plausible_alternatives\": \", \".join(c[\"plausible_alternatives\"]) if c[\"plausible_alternatives\"] else \"\",\n    \"symptoms\": \"; \".join([f\"{d}:{s}\" for d,s in c[\"symptoms\"]]),\n    \"red_flags\": \", \".join(c[\"red_flags\"]) if c[\"red_flags\"] else \"\",\n    \"missing_info\": \", \".join(c[\"missing_info_list\"]) if c[\"missing_info_list\"] else \"\",\n    \"should_defer\": c[\"labels\"][\"should_defer\"],\n    \"risk_high\": c[\"labels\"][\"risk_high\"],\n    # cognitive scores\n    \"cog_verbal_language\": c[\"cognitive_profile\"][\"verbal_language\"],\n    \"cog_visuospatial\": c[\"cognitive_profile\"][\"visuospatial\"],\n    \"cog_working_memory\": c[\"cognitive_profile\"][\"working_memory\"],\n    \"cog_processing_speed\": c[\"cognitive_profile\"][\"processing_speed\"],\n    \"cog_attention\": c[\"cognitive_profile\"][\"attention\"],\n    \"cog_motor\": c[\"cognitive_profile\"][\"motor\"],\n    \"cognitive_pattern\": c[\"cognitive_pattern\"],\n} for c in cases])\n\nprint(\"Dataset shape:\", df.shape)\nprint(\"\\nClass balance (true_profile):\")\nprint(df[\"true_profile\"].value_counts(normalize=True).round(3))\nprint(\"\\nDefer rate:\", round(df[\"should_defer\"].mean(), 3), \" | High-risk rate:\", round(df[\"risk_high\"].mean(), 3))\n\nprint(\"Defer rate:\", df[\"should_defer\"].mean().round(3))\nprint(df.groupby(\"true_profile\")[\"should_defer\"].mean().round(3).sort_values(ascending=False))\n\n\nprint(df.groupby(\"true_profile\")[[\n    \"cog_verbal_language\",\"cog_visuospatial\",\"cog_working_memory\",\n    \"cog_processing_speed\",\"cog_attention\",\"cog_motor\"\n]].mean().round(2))\n\ndf.head()\n\nN = N_CASES\nNOISE_LEVEL = NOISE_LEVEL\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (2000, 21)\n",
      "\n",
      "Class balance (true_profile):\n",
      "true_profile\n",
      "ASD                 0.189\n",
      "ADHD                0.180\n",
      "ANXIETY             0.158\n",
      "SLD                 0.142\n",
      "OCD                 0.112\n",
      "SELECTIVE_MUTISM    0.082\n",
      "NDD_UNSPEC          0.072\n",
      "GDD_ID              0.066\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Defer rate: 0.564  | High-risk rate: 0.032\n",
      "Defer rate: 0.564\n",
      "true_profile\n",
      "NDD_UNSPEC          0.703\n",
      "ADHD                0.657\n",
      "ANXIETY             0.575\n",
      "ASD                 0.545\n",
      "OCD                 0.529\n",
      "SELECTIVE_MUTISM    0.506\n",
      "SLD                 0.486\n",
      "GDD_ID              0.485\n",
      "Name: should_defer, dtype: float64\n",
      "                  cog_verbal_language  cog_visuospatial  cog_working_memory  \\\n",
      "true_profile                                                                  \n",
      "ADHD                             9.45              9.53                7.10   \n",
      "ANXIETY                          9.32              9.39                8.52   \n",
      "ASD                              7.73             10.92                6.72   \n",
      "GDD_ID                           3.48              3.35                3.49   \n",
      "NDD_UNSPEC                       7.41              7.33                7.61   \n",
      "OCD                             11.53              9.66                9.49   \n",
      "SELECTIVE_MUTISM                 8.85              9.49                8.60   \n",
      "SLD                              9.56              9.36                9.31   \n",
      "\n",
      "                  cog_processing_speed  cog_attention  cog_motor  \n",
      "true_profile                                                      \n",
      "ADHD                              6.87           5.10       9.63  \n",
      "ANXIETY                           7.48           8.78       9.50  \n",
      "ASD                               6.13           7.79       8.53  \n",
      "GDD_ID                            3.52           3.37       3.44  \n",
      "NDD_UNSPEC                        7.35           8.07       7.37  \n",
      "OCD                               7.34           9.47       9.49  \n",
      "SELECTIVE_MUTISM                  7.45           8.48       9.09  \n",
      "SLD                               9.35           9.55       9.49  \n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vignette text + follow-up questions\n\nTurn the structured fields into a short referral-style vignette and a small set of follow-up questions.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T15:33:05.411047Z",
     "start_time": "2026-02-10T15:33:05.098356Z"
    }
   },
   "source": [
    "import random\n",
    "import textwrap\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "\n",
    "# utility: estrai sintomi per dominio dalla stringa \"dom:sym; dom:sym; ...\"\n",
    "def parse_symptoms(symptom_str):\n",
    "    items = []\n",
    "    if not isinstance(symptom_str, str) or symptom_str.strip() == \"\":\n",
    "        return items\n",
    "    for part in symptom_str.split(\";\"):\n",
    "        part = part.strip()\n",
    "        if \":\" in part:\n",
    "            dom, sym = part.split(\":\", 1)\n",
    "            items.append((dom.strip(), sym.strip()))\n",
    "        else:\n",
    "            items.append((\"general\", part.strip()))\n",
    "    return items\n",
    "\n",
    "def pretty_list(xs, max_items=4):\n",
    "    xs = [x for x in xs if x]\n",
    "    if len(xs) == 0:\n",
    "        return \"\"\n",
    "    xs = xs[:max_items]\n",
    "    if len(xs) == 1:\n",
    "        return xs[0]\n",
    "    if len(xs) == 2:\n",
    "        return f\"{xs[0]} and {xs[1]}\"\n",
    "    return \", \".join(xs[:-1]) + f\", and {xs[-1]}\"\n",
    "\n",
    "def cognitive_sentence(row):\n",
    "    # converte punteggi in una frase leggibile\n",
    "    vl = row[\"cog_verbal_language\"]\n",
    "    vs = row[\"cog_visuospatial\"]\n",
    "    wm = row[\"cog_working_memory\"]\n",
    "    ps = row[\"cog_processing_speed\"]\n",
    "    att = row[\"cog_attention\"]\n",
    "    mot = row[\"cog_motor\"]\n",
    "    pattern = row[\"cognitive_pattern\"]\n",
    "\n",
    "    # qualche descrittore semplice (evita claim clinici forti)\n",
    "    def band(x):\n",
    "        if x <= 4: return \"markedly low\"\n",
    "        if x <= 7: return \"below average\"\n",
    "        if x <= 12: return \"average\"\n",
    "        return \"above average\"\n",
    "\n",
    "    if pattern == \"homogeneous_low\":\n",
    "        return (f\"Cognitive screening suggests a globally reduced profile across domains \"\n",
    "                f\"(verbal {band(vl)}, visuospatial {band(vs)}, working memory {band(wm)}, \"\n",
    "                f\"processing speed {band(ps)}, attention {band(att)}, motor {band(mot)}).\")\n",
    "    elif pattern == \"homogeneous_average\":\n",
    "        return (f\"Cognitive screening is broadly even across domains \"\n",
    "                f\"(verbal {band(vl)}, visuospatial {band(vs)}, working memory {band(wm)}, \"\n",
    "                f\"processing speed {band(ps)}, attention {band(att)}, motor {band(mot)}).\")\n",
    "    else:\n",
    "        # dishomogeneous\n",
    "        # evidenzia punto di forza e debolezza\n",
    "        scores = {\n",
    "            \"verbal/language\": vl,\n",
    "            \"visuospatial\": vs,\n",
    "            \"working memory\": wm,\n",
    "            \"processing speed\": ps,\n",
    "            \"attention\": att,\n",
    "            \"motor\": mot\n",
    "        }\n",
    "        strongest = max(scores, key=scores.get)\n",
    "        weakest = min(scores, key=scores.get)\n",
    "        return (f\"Cognitive screening indicates a heterogeneous profile, with a relative strength in {strongest} \"\n",
    "                f\"and a relative weakness in {weakest} (other domains fall in the {band( (vl+vs+wm+ps+att+mot)/6 )} range).\")\n",
    "\n",
    "# mapping “missing_info” -> domande\n",
    "MISSING_TO_QUESTIONS = {\n",
    "    \"onset timeline\": [\n",
    "        \"When did the difficulties first emerge, and was the onset sudden or gradual?\",\n",
    "        \"Were there any early developmental concerns (language, play, social engagement)?\"\n",
    "    ],\n",
    "    \"functional impairment details\": [\n",
    "        \"How do the difficulties affect daily functioning at home, school, and with peers?\",\n",
    "        \"Which situations lead to the most impairment (transitions, homework, social demands)?\"\n",
    "    ],\n",
    "    \"cross-setting symptoms (home vs school)\": [\n",
    "        \"Are the symptoms present across settings (home, school, community), or situation-specific?\",\n",
    "        \"What differences do caregivers and teachers report?\"\n",
    "    ],\n",
    "    \"teacher report\": [\n",
    "        \"Could we obtain a teacher report describing classroom behavior and learning progress?\",\n",
    "        \"Are there standardized school observations or rating scales available?\"\n",
    "    ],\n",
    "    \"developmental history\": [\n",
    "        \"Can we review developmental milestones (language, motor, adaptive skills) and early social communication?\",\n",
    "        \"Any relevant perinatal/medical history?\"\n",
    "    ],\n",
    "    \"language/pragmatics assessment\": [\n",
    "        \"Is a language and pragmatic communication assessment available (including social use of language)?\",\n",
    "        \"Any concerns about speech production, comprehension, or narrative skills?\"\n",
    "    ],\n",
    "    \"learning assessment (reading/writing/math)\": [\n",
    "        \"Have reading, writing, and math skills been formally assessed (psychoeducational testing)?\",\n",
    "        \"What was the response to targeted school interventions?\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# prompt scaffolding: variability linguistica minima per non fare template troppo rigido\n",
    "OPENERS = [\n",
    "    \"A child is referred for evaluation due to concerns about functioning in everyday contexts.\",\n",
    "    \"A pediatric neurodevelopmental evaluation is requested based on caregiver and school concerns.\",\n",
    "    \"This case describes a child presenting with developmental and behavioral concerns.\"\n",
    "]\n",
    "CONTEXT_SENT = {\n",
    "    \"preschool\": [\n",
    "        \"The child is currently attending preschool.\",\n",
    "        \"The child is in a preschool setting.\"\n",
    "    ],\n",
    "    \"primary school\": [\n",
    "        \"The child is currently attending primary school.\",\n",
    "        \"The child is in a primary school setting.\"\n",
    "    ],\n",
    "    \"home+school\": [\n",
    "        \"Concerns are reported across both home and school contexts.\",\n",
    "        \"Difficulties are described in multiple settings, including home and school.\"\n",
    "    ]\n",
    "}\n",
    "SEVERITY_SENT = {\n",
    "    \"mild\": [\n",
    "        \"Overall severity is described as mild, though specific situations can be challenging.\",\n",
    "        \"Difficulties are mild overall, with noticeable impact in select contexts.\"\n",
    "    ],\n",
    "    \"moderate\": [\n",
    "        \"Overall severity is described as moderate, with meaningful impact on daily routines.\",\n",
    "        \"Difficulties are of moderate severity and interfere with daily functioning.\"\n",
    "    ],\n",
    "    \"severe\": [\n",
    "        \"Overall severity is described as severe, with substantial functional impact.\",\n",
    "        \"Difficulties are severe and significantly disrupt daily functioning.\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "def build_vignette(row):\n",
    "    age = int(row[\"age\"])\n",
    "    sex = row[\"sex\"]\n",
    "    context = row[\"context\"]\n",
    "    duration = row[\"duration\"]\n",
    "    severity = row[\"severity\"]\n",
    "\n",
    "    sym_items = parse_symptoms(row[\"symptoms\"])\n",
    "    # scegli 4-6 sintomi da citare\n",
    "    random.shuffle(sym_items)\n",
    "    sym_items = sym_items[:min(len(sym_items), random.choice([4,5,6]))]\n",
    "    sym_phrases = [s for d,s in sym_items]\n",
    "    symptoms_text = pretty_list(sym_phrases, max_items=6)\n",
    "\n",
    "    # red flags: menzionali senza dettagli sensazionalistici\n",
    "    red = row[\"red_flags\"]\n",
    "    red_text = \"\"\n",
    "    if isinstance(red, str) and red.strip():\n",
    "        red_text = \" A safety screen notes a potential red-flag item that warrants clinical attention.\"\n",
    "\n",
    "    cog_text = cognitive_sentence(row)\n",
    "\n",
    "    missing = row[\"missing_info\"] if isinstance(row[\"missing_info\"], str) else \"\"\n",
    "    missing_list = [m.strip() for m in missing.split(\",\") if m.strip()]\n",
    "    if len(missing_list) > 0:\n",
    "        missing_note = f\" Key information is currently missing (e.g., {pretty_list(missing_list, max_items=3)}), which increases uncertainty.\"\n",
    "    else:\n",
    "        missing_note = \" Available information is reasonably complete, though further clarification may still be helpful.\"\n",
    "\n",
    "    opener = random.choice(OPENERS)\n",
    "    ctx_sent = random.choice(CONTEXT_SENT.get(context, [\"The child is currently in school.\"]))\n",
    "    sev_sent = random.choice(SEVERITY_SENT.get(severity, [\"Severity is variable.\"]))\n",
    "\n",
    "    vignette = (\n",
    "        f\"{opener} \"\n",
    "        f\"The patient is a {age}-year-old {('boy' if sex=='M' else 'girl')}. {ctx_sent} \"\n",
    "        f\"Reported concerns have been present for {duration}. {sev_sent} \"\n",
    "        f\"Core features include {symptoms_text}.{red_text}\\n\\n\"\n",
    "        f\"{cog_text}\\n\\n\"\n",
    "        f\"{missing_note}\"\n",
    "    )\n",
    "\n",
    "    # wrap leggero (opzionale)\n",
    "    return textwrap.fill(vignette, width=110)\n",
    "\n",
    "def build_questions(row, max_q=5):\n",
    "    missing = row[\"missing_info\"] if isinstance(row[\"missing_info\"], str) else \"\"\n",
    "    missing_list = [m.strip() for m in missing.split(\",\") if m.strip()]\n",
    "    qs = []\n",
    "    for m in missing_list:\n",
    "        qs.extend(MISSING_TO_QUESTIONS.get(m, []))\n",
    "    # se poche info mancanti, aggiungi domande “generiche” sensate\n",
    "    if len(qs) < 2:\n",
    "        qs.extend([\n",
    "            \"What are the child's strengths and which situations are most successful?\",\n",
    "            \"Are there any prior assessments or interventions, and what was the response?\"\n",
    "        ])\n",
    "    # dedup + sample\n",
    "    seen = set()\n",
    "    qs2 = []\n",
    "    for q in qs:\n",
    "        if q not in seen:\n",
    "            seen.add(q)\n",
    "            qs2.append(q)\n",
    "    random.shuffle(qs2)\n",
    "    return qs2[:max_q]\n",
    "\n",
    "# Aggiungi colonne testuali\n",
    "df = df.copy()\n",
    "df[\"vignette_en\"] = df.apply(build_vignette, axis=1)\n",
    "df[\"questions_to_ask_en\"] = df.apply(lambda r: build_questions(r, max_q=5), axis=1)\n",
    "\n",
    "# (opzionale) rationale breve per should_defer, utile per LLM supervision\n",
    "def build_rationale(row):\n",
    "    if int(row[\"risk_high\"]) == 1:\n",
    "        return \"Defer: a red-flag item requires clinician-led risk assessment.\"\n",
    "    missing = row[\"missing_info\"] if isinstance(row[\"missing_info\"], str) else \"\"\n",
    "    if int(row[\"should_defer\"]) == 1:\n",
    "        if missing.strip():\n",
    "            return f\"Defer: missing key information ({missing}) increases diagnostic uncertainty.\"\n",
    "        return \"Defer: uncertainty is high; additional clinical information is needed before decisions.\"\n",
    "    return \"No defer: available information supports a tentative working hypothesis, with routine follow-up questions.\"\n",
    "\n",
    "df[\"should_defer_rationale_en\"] = df.apply(build_rationale, axis=1)\n",
    "\n",
    "df[[\"true_profile\",\"should_defer\",\"vignette_en\",\"questions_to_ask_en\"]].head(3)\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       true_profile  should_defer  \\\n",
       "0               SLD             0   \n",
       "1           ANXIETY             1   \n",
       "2  SELECTIVE_MUTISM             0   \n",
       "\n",
       "                                         vignette_en  \\\n",
       "0  A child is referred for evaluation due to conc...   \n",
       "1  A child is referred for evaluation due to conc...   \n",
       "2  This case describes a child presenting with de...   \n",
       "\n",
       "                                 questions_to_ask_en  \n",
       "0  [Have reading, writing, and math skills been f...  \n",
       "1  [When did the difficulties first emerge, and w...  \n",
       "2  [Any concerns about speech production, compreh...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true_profile</th>\n",
       "      <th>should_defer</th>\n",
       "      <th>vignette_en</th>\n",
       "      <th>questions_to_ask_en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SLD</td>\n",
       "      <td>0</td>\n",
       "      <td>A child is referred for evaluation due to conc...</td>\n",
       "      <td>[Have reading, writing, and math skills been f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ANXIETY</td>\n",
       "      <td>1</td>\n",
       "      <td>A child is referred for evaluation due to conc...</td>\n",
       "      <td>[When did the difficulties first emerge, and w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SELECTIVE_MUTISM</td>\n",
       "      <td>0</td>\n",
       "      <td>This case describes a child presenting with de...</td>\n",
       "      <td>[Any concerns about speech production, compreh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/val/test split + export\n\nCreate stratified splits and write outputs to `data/`.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T15:40:42.161768Z",
     "start_time": "2026-02-10T15:40:41.982792Z"
    }
   },
   "source": [
    "from pathlib import Path\n",
    "from datetime import datetime, timezone\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "\n",
    "# -----------------------------\n",
    "# Paths\n",
    "# -----------------------------\n",
    "DATA_DIR = Path(\"../data\")\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# -----------------------------\n",
    "# Train / Val / Test split\n",
    "# -----------------------------\n",
    "train_df, temp_df = train_test_split(\n",
    "    df,\n",
    "    test_size=0.30,\n",
    "    random_state=SEED,\n",
    "    stratify=df[\"true_profile\"]\n",
    ")\n",
    "\n",
    "val_df, test_df = train_test_split(\n",
    "    temp_df,\n",
    "    test_size=0.50,\n",
    "    random_state=SEED,\n",
    "    stratify=temp_df[\"true_profile\"]\n",
    ")\n",
    "\n",
    "print(\"Train:\", train_df.shape, \"Val:\", val_df.shape, \"Test:\", test_df.shape)\n",
    "\n",
    "# -----------------------------\n",
    "# Save CSV\n",
    "# -----------------------------\n",
    "df.to_csv(DATA_DIR / \"neurodevdiff_v1_full.csv\", index=False)\n",
    "train_df.to_csv(DATA_DIR / \"neurodevdiff_v1_train.csv\", index=False)\n",
    "val_df.to_csv(DATA_DIR / \"neurodevdiff_v1_val.csv\", index=False)\n",
    "test_df.to_csv(DATA_DIR / \"neurodevdiff_v1_test.csv\", index=False)\n",
    "\n",
    "# -----------------------------\n",
    "# JSONL (LLM-friendly)\n",
    "# -----------------------------\n",
    "def to_jsonl(df_part, path):\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        for _, r in df_part.iterrows():\n",
    "            record = {\n",
    "                \"input\": r[\"vignette_en\"],\n",
    "                \"output\": {\n",
    "                    \"should_defer\": int(r[\"should_defer\"]),\n",
    "                    \"rationale\": r[\"should_defer_rationale_en\"],\n",
    "                    \"questions_to_ask\": r[\"questions_to_ask_en\"],\n",
    "                    \"differential_hypotheses\": (\n",
    "                        [r[\"true_profile\"]] +\n",
    "                        [x.strip() for x in str(r[\"plausible_alternatives\"]).split(\",\") if x.strip()][:2]\n",
    "                    )\n",
    "                },\n",
    "                \"meta\": {\n",
    "                    \"true_profile\": r[\"true_profile\"],\n",
    "                    \"risk_high\": int(r[\"risk_high\"]),\n",
    "                    \"severity\": r[\"severity\"],\n",
    "                    \"age\": int(r[\"age\"]),\n",
    "                    \"sex\": r[\"sex\"]\n",
    "                }\n",
    "            }\n",
    "            f.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "to_jsonl(train_df, DATA_DIR / \"neurodevdiff_v1_train.jsonl\")\n",
    "to_jsonl(val_df,   DATA_DIR / \"neurodevdiff_v1_val.jsonl\")\n",
    "to_jsonl(test_df,  DATA_DIR / \"neurodevdiff_v1_test.jsonl\")\n",
    "\n",
    "# -----------------------------\n",
    "# Metadata\n",
    "# -----------------------------\n",
    "meta = {\n",
    "    \"dataset\": \"NeuroDevDiff\",\n",
    "    \"version\": \"1\",\n",
    "    \"n_cases\": int(len(df)),\n",
    "    \"seed\": int(SEED),\n",
    "    \"noise_level\": float(NOISE_LEVEL),\n",
    "    \"class_balance\": df[\"true_profile\"].value_counts(normalize=True).round(4).to_dict(),\n",
    "    \"defer_rate\": float(df[\"should_defer\"].mean()),\n",
    "    \"risk_high_rate\": float(df[\"risk_high\"].mean()),\n",
    "    \"created_utc\": datetime.now(timezone.utc).isoformat(timespec=\"seconds\"),\n",
    "}\n",
    "\n",
    "with open(DATA_DIR / \"neurodevdiff_v1_metadata.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(meta, f, indent=2)\n",
    "\n",
    "print(\"Saved dataset to:\", DATA_DIR.resolve())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (1400, 24) Val: (300, 24) Test: (300, 24)\n",
      "Saved dataset to: /Users/galvari/Desktop/RandomJobs/NDD/NeuroDevDiff/data\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ]
}
